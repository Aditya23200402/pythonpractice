{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.0.1-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Downloading numpy-2.0.1-cp312-cp312-win_amd64.whl (16.3 MB)\n",
      "   ---------------------------------------- 0.0/16.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/16.3 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/16.3 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/16.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/16.3 MB 560.1 kB/s eta 0:00:29\n",
      "   - -------------------------------------- 0.8/16.3 MB 763.2 kB/s eta 0:00:21\n",
      "   -- ------------------------------------- 1.0/16.3 MB 868.0 kB/s eta 0:00:18\n",
      "   -- ------------------------------------- 1.0/16.3 MB 868.0 kB/s eta 0:00:18\n",
      "   --- ------------------------------------ 1.3/16.3 MB 818.6 kB/s eta 0:00:19\n",
      "   --- ------------------------------------ 1.6/16.3 MB 865.2 kB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 1.8/16.3 MB 898.8 kB/s eta 0:00:17\n",
      "   ----- ---------------------------------- 2.1/16.3 MB 896.4 kB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 2.1/16.3 MB 896.4 kB/s eta 0:00:16\n",
      "   ------ --------------------------------- 2.6/16.3 MB 949.8 kB/s eta 0:00:15\n",
      "   ------- -------------------------------- 2.9/16.3 MB 987.0 kB/s eta 0:00:14\n",
      "   ------- -------------------------------- 3.1/16.3 MB 1.0 MB/s eta 0:00:13\n",
      "   --------- ------------------------------ 3.7/16.3 MB 1.1 MB/s eta 0:00:12\n",
      "   ---------- ----------------------------- 4.2/16.3 MB 1.2 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 4.2/16.3 MB 1.2 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 4.7/16.3 MB 1.2 MB/s eta 0:00:10\n",
      "   ------------ --------------------------- 5.0/16.3 MB 1.2 MB/s eta 0:00:10\n",
      "   ------------ --------------------------- 5.0/16.3 MB 1.2 MB/s eta 0:00:10\n",
      "   ------------ --------------------------- 5.2/16.3 MB 1.2 MB/s eta 0:00:10\n",
      "   ------------- -------------------------- 5.5/16.3 MB 1.1 MB/s eta 0:00:10\n",
      "   -------------- ------------------------- 5.8/16.3 MB 1.2 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 6.0/16.3 MB 1.1 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 6.0/16.3 MB 1.1 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 6.3/16.3 MB 1.1 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 6.3/16.3 MB 1.1 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 6.6/16.3 MB 1.1 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 6.6/16.3 MB 1.1 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 6.8/16.3 MB 1.1 MB/s eta 0:00:09\n",
      "   ----------------- ---------------------- 7.1/16.3 MB 1.1 MB/s eta 0:00:09\n",
      "   ------------------ --------------------- 7.3/16.3 MB 1.1 MB/s eta 0:00:09\n",
      "   ------------------ --------------------- 7.6/16.3 MB 1.1 MB/s eta 0:00:09\n",
      "   ------------------ --------------------- 7.6/16.3 MB 1.1 MB/s eta 0:00:09\n",
      "   ------------------- -------------------- 7.9/16.3 MB 1.1 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 7.9/16.3 MB 1.1 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 8.1/16.3 MB 1.0 MB/s eta 0:00:08\n",
      "   -------------------- ------------------- 8.4/16.3 MB 1.0 MB/s eta 0:00:08\n",
      "   --------------------- ------------------ 8.7/16.3 MB 1.0 MB/s eta 0:00:08\n",
      "   --------------------- ------------------ 8.9/16.3 MB 1.0 MB/s eta 0:00:08\n",
      "   ---------------------- ----------------- 9.2/16.3 MB 1.0 MB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 9.2/16.3 MB 1.0 MB/s eta 0:00:07\n",
      "   ----------------------- ---------------- 9.4/16.3 MB 1.0 MB/s eta 0:00:07\n",
      "   ----------------------- ---------------- 9.7/16.3 MB 1.0 MB/s eta 0:00:07\n",
      "   ----------------------- ---------------- 9.7/16.3 MB 1.0 MB/s eta 0:00:07\n",
      "   ------------------------ --------------- 10.0/16.3 MB 1.0 MB/s eta 0:00:07\n",
      "   ------------------------ --------------- 10.0/16.3 MB 1.0 MB/s eta 0:00:07\n",
      "   ------------------------- -------------- 10.2/16.3 MB 999.3 kB/s eta 0:00:07\n",
      "   ------------------------- -------------- 10.5/16.3 MB 989.9 kB/s eta 0:00:06\n",
      "   ------------------------- -------------- 10.5/16.3 MB 989.9 kB/s eta 0:00:06\n",
      "   -------------------------- ------------- 10.7/16.3 MB 984.0 kB/s eta 0:00:06\n",
      "   -------------------------- ------------- 10.7/16.3 MB 984.0 kB/s eta 0:00:06\n",
      "   --------------------------- ------------ 11.0/16.3 MB 963.4 kB/s eta 0:00:06\n",
      "   --------------------------- ------------ 11.0/16.3 MB 963.4 kB/s eta 0:00:06\n",
      "   --------------------------- ------------ 11.3/16.3 MB 960.1 kB/s eta 0:00:06\n",
      "   --------------------------- ------------ 11.3/16.3 MB 960.1 kB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 11.5/16.3 MB 938.2 kB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 11.5/16.3 MB 938.2 kB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 11.8/16.3 MB 934.5 kB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 11.8/16.3 MB 934.5 kB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 11.8/16.3 MB 934.5 kB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 12.1/16.3 MB 903.1 kB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 12.1/16.3 MB 903.1 kB/s eta 0:00:05\n",
      "   ------------------------------ --------- 12.3/16.3 MB 896.4 kB/s eta 0:00:05\n",
      "   ------------------------------ --------- 12.6/16.3 MB 901.2 kB/s eta 0:00:05\n",
      "   ------------------------------- -------- 12.8/16.3 MB 907.9 kB/s eta 0:00:04\n",
      "   ------------------------------- -------- 12.8/16.3 MB 907.9 kB/s eta 0:00:04\n",
      "   -------------------------------- ------- 13.1/16.3 MB 894.6 kB/s eta 0:00:04\n",
      "   -------------------------------- ------- 13.1/16.3 MB 894.6 kB/s eta 0:00:04\n",
      "   -------------------------------- ------- 13.4/16.3 MB 892.4 kB/s eta 0:00:04\n",
      "   --------------------------------- ------ 13.6/16.3 MB 895.9 kB/s eta 0:00:03\n",
      "   --------------------------------- ------ 13.6/16.3 MB 895.9 kB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 13.9/16.3 MB 889.3 kB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 14.2/16.3 MB 888.3 kB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 14.2/16.3 MB 888.3 kB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 14.2/16.3 MB 888.3 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 14.4/16.3 MB 872.0 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 14.4/16.3 MB 872.0 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 14.7/16.3 MB 869.7 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 14.9/16.3 MB 868.3 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 15.2/16.3 MB 873.4 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 15.2/16.3 MB 873.4 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 15.5/16.3 MB 872.0 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 15.7/16.3 MB 870.6 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 15.7/16.3 MB 870.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------  16.0/16.3 MB 870.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  16.0/16.3 MB 870.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 16.3/16.3 MB 863.8 kB/s eta 0:00:00\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-2.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.2-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.2-cp312-cp312-win_amd64.whl (11.5 MB)\n",
      "   ---------------------------------------- 0.0/11.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/11.5 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/11.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/11.5 MB 1.0 MB/s eta 0:00:11\n",
      "   - -------------------------------------- 0.5/11.5 MB 1.0 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 0.8/11.5 MB 799.2 kB/s eta 0:00:14\n",
      "   --- ------------------------------------ 1.0/11.5 MB 898.8 kB/s eta 0:00:12\n",
      "   ---- ----------------------------------- 1.3/11.5 MB 972.7 kB/s eta 0:00:11\n",
      "   ------ --------------------------------- 1.8/11.5 MB 1.1 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 1.8/11.5 MB 1.1 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 2.1/11.5 MB 1.0 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 2.4/11.5 MB 993.9 kB/s eta 0:00:10\n",
      "   --------- ------------------------------ 2.6/11.5 MB 1.1 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 2.9/11.5 MB 1.1 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 3.1/11.5 MB 1.1 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 3.7/11.5 MB 1.2 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 3.9/11.5 MB 1.2 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 4.2/11.5 MB 1.2 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 4.2/11.5 MB 1.2 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 4.5/11.5 MB 1.1 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 4.7/11.5 MB 1.1 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 5.2/11.5 MB 1.2 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 5.5/11.5 MB 1.2 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 5.8/11.5 MB 1.2 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 6.3/11.5 MB 1.2 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 6.6/11.5 MB 1.3 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 7.1/11.5 MB 1.3 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 7.6/11.5 MB 1.3 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 7.9/11.5 MB 1.3 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 8.4/11.5 MB 1.4 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 8.7/11.5 MB 1.4 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 8.9/11.5 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 9.2/11.5 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 9.2/11.5 MB 1.4 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 9.7/11.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 10.0/11.5 MB 1.4 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 10.2/11.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.5/11.5 MB 1.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.0/11.5 MB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.0/11.5 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.3/11.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.3/11.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.5/11.5 MB 1.3 MB/s eta 0:00:00\n",
      "Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.2.2 pytz-2024.1 tzdata-2024.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df  = pd.read_csv('https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv')\n",
    "df = df[(df.variety == \"Iris-Virginica\") & (df['petal.length'] > 1.5)]\n",
    "for i in df.values:\n",
    "    print(i[0], i[1],i[2], i[3], i[4])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['sepal.length', 'sepal.width', 'petal.length', 'petal.width',\n",
      "       'variety'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 50 50\n"
     ]
    }
   ],
   "source": [
    "print(int(df.variety.value_counts()['Setosa']), int(df.variety.value_counts()['Versicolor']), int(df.variety.value_counts()['Virginica']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.30 2.30 1.00 0.10 Iris-setosa\n",
      "5.80 4.40 1.90 0.60 Iris-setosa\n",
      "5.01 3.42 1.46 0.24 Iris-setosa\n",
      "4.90 2.00 3.00 1.00 Iris-versicolor\n",
      "7.00 3.40 5.10 1.80 Iris-versicolor\n",
      "5.94 2.77 4.26 1.33 Iris-versicolor\n",
      "4.90 2.20 4.50 1.40 Iris-virginica\n",
      "7.90 3.80 6.90 2.50 Iris-virginica\n",
      "6.59 2.97 5.55 2.03 Iris-virginica\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd   \n",
    "data_file=pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data',header=None)\n",
    "data_file.columns = ['sl', 'sw', 'pl', 'pw', 'flower_type']\n",
    "\n",
    "for n in  ['Iris-setosa','Iris-versicolor','Iris-virginica']:\n",
    "    file = data_file[data_file.flower_type == n]\n",
    "    data = file.describe()\n",
    "    data.loc['avg'] = [sum(file.sl)/50.0, sum(file.sw)/50.0, sum(file.pl)/50.0, sum(file.pw)/50.0]\n",
    "\n",
    "    for i in ['min','max','avg']:\n",
    "        for j in ['sl','sw','pl','pw']:\n",
    "            print('%.2f'%data[j][i],end=\" \")\n",
    "        print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Srinagar 657 Muslim Separatists\n"
     ]
    }
   ],
   "source": [
    "#terrorism count\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv('terrorismData.csv')\n",
    "df = df[df.State == 'Jammu and Kashmir']\n",
    "df=df[df.City==df.City.describe().top]\n",
    "count = df.shape[0]\n",
    "df = df[df.Group != \"Unknown\"]\n",
    "city = df.City.describe().top\n",
    "group=df.Group.describe().top\n",
    "print(city, count, group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "India 351 1990\n"
     ]
    }
   ],
   "source": [
    "df=df[df.Country==df.Country.describe().top]\n",
    "count = df.shape[0]\n",
    "country = df.Country.describe().top\n",
    "y = {}\n",
    "for i in df.Year:\n",
    "    if i in y.keys():\n",
    "        y[i] += 1\n",
    "    else:\n",
    "        y[i] = 1\n",
    "cnt=0\n",
    "year=0\n",
    "for i in y.keys():\n",
    "    if cnt<y[i]:\n",
    "        cnt=y[i]\n",
    "        year=i\n",
    "print(country, count, year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5628\n"
     ]
    }
   ],
   "source": [
    "# Terror casualty Red corridor\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "with open('terrorismData.csv', encoding='utf8') as file:\n",
    " data=csv.DictReader(file,skipinitialspace=True)\n",
    " State=[]\n",
    " Killed=[]\n",
    " Wounded=[]\n",
    "\n",
    "\n",
    " for r in data:\n",
    "    State.append(r['State'])\n",
    "    Killed.append(r['Killed'])\n",
    "    Wounded.append(r['Wounded'])\n",
    "    \n",
    " np_killed=np.array(Killed)\n",
    " np_killed[np_killed=='']='0.0'\n",
    " np_killed=np.array(np_killed,dtype=float)\n",
    "\n",
    " np_Wounded=np.array(Wounded)\n",
    " np_Wounded[np_Wounded=='']='0.0'\n",
    " np_Wounded=np.array(np_Wounded,dtype=float)\n",
    "\n",
    " Casualty = np.array(np_killed+np_Wounded,dtype=int)\n",
    "    \n",
    " np_State=np.array(State)    \n",
    "\n",
    " np_bool =(np_State =='Jharkhand') | (np_State=='Odisha') |(np_State=='Andhra Pradesh')|(np_State=='Chhattisgarh')\n",
    "\n",
    " print(sum(Casualty[np_bool]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Srinagar 3134\n",
      "New Delhi 2095\n",
      "Mumbai 2016\n",
      "Jammu 1119\n",
      "Guwahati 822\n"
     ]
    }
   ],
   "source": [
    "#Terrorism city casualty for top 5 cities\n",
    "\n",
    "import numpy as np\n",
    "import csv\n",
    "with open('terrorismData.csv', encoding='utf8') as file_obj:\n",
    "    file_data = csv.DictReader(file_obj, skipinitialspace=True)\n",
    "    killed = []\n",
    "    wounded=[]\n",
    "    city = []\n",
    "    for row in file_data:\n",
    "        if 'India' in row['Country'] and 'Unknown' not in row['City']:\n",
    "            city.append(row['City'])\n",
    "            wounded.append(row['Wounded'])\n",
    "            killed.append(row['Killed'])\n",
    "np_city = np.array(city)\n",
    "np_killed= np.array(killed)\n",
    "np_wounded = np.array(wounded)\n",
    "np_killed[np_killed=='']='0.0'\n",
    "np_wounded[np_wounded=='']='0.0'\n",
    "np_killed=np.array(np_killed, dtype='float')\n",
    "np_wounded=np.array(np_wounded, dtype='float')\n",
    "np_casuality=np.array(np_wounded+np_killed, dtype='int')\n",
    "\n",
    "citydict = {}\n",
    "for i in range(len(np_city)):\n",
    "    if np_city[i] in citydict:\n",
    "       citydict[np_city[i]] += np_casuality[i]\n",
    "    else:\n",
    "        citydict[np_city[i]]=np_casuality[i]\n",
    "\n",
    "count = 0\n",
    "city =''\n",
    "for i in citydict:\n",
    "    if citydict[i]>count:\n",
    "        count=citydict[i]\n",
    "        city=i\n",
    "print(city,count)\n",
    "del citydict[city]\n",
    "\n",
    "count = 0\n",
    "city =''\n",
    "for i in citydict:\n",
    "    if citydict[i]>count:\n",
    "        count=citydict[i]\n",
    "        city=i\n",
    "print(city,count)\n",
    "del citydict[city]\n",
    "\n",
    "count = 0\n",
    "city =''\n",
    "for i in citydict:\n",
    "    if citydict[i]>count:\n",
    "        count=citydict[i]\n",
    "        city=i\n",
    "print(city,count)\n",
    "del citydict[city]\n",
    "\n",
    "count = 0\n",
    "city =''\n",
    "for i in citydict:\n",
    "    if citydict[i]>count:\n",
    "        count=citydict[i]\n",
    "        city=i\n",
    "print(city,count)\n",
    "del citydict[city]\n",
    "\n",
    "count = 0\n",
    "city =''\n",
    "for i in citydict:\n",
    "    if citydict[i]>count:\n",
    "        count=citydict[i]\n",
    "        city=i\n",
    "print(city,count)\n",
    "del citydict[city]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terrorism FrequentDay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 6500\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "with open('terrorismData.csv', encoding='utf8') as file_obj:\n",
    "    file_data = csv.DictReader(file_obj, skipinitialspace=True)\n",
    "    day =[]\n",
    "    for row in file_data:\n",
    "        day.append(row['Day'])\n",
    "    np_day = np.array(day, dtype=int)\n",
    "    day, count=np.unique(np_day, return_counts=True)\n",
    "    print(day[np.argmax(count)], count[np.argmax(count)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terror deadliest attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1570 Iraq Islamic State of Iraq and the Levant (ISIL)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('terrorismData.csv')\n",
    "df =df[df.Killed == df.Killed.max()]\n",
    "killed = df.Killed.iloc[0]\n",
    "country = df.Country.iloc[0]\n",
    "group = df.Group.iloc[0]\n",
    "print(int(killed), country, group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terror Government"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3336 Maoists\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('terrorismData.csv')\n",
    "a = df[df.Day>=26]\n",
    "b = a[a.Year == 2014]\n",
    "c = b[b.Country == 'India']\n",
    "ans1 = c[c.Month==5]\n",
    "del a\n",
    "del b\n",
    "del c\n",
    "a = df[df.Year == 2014]\n",
    "b = a[a.Country == 'India']\n",
    "ans2 = b[b.Month > 5]\n",
    "del a\n",
    "del b\n",
    "a = df[df.Country == 'India']\n",
    "ans3 = a[a.Year > 2014]\n",
    "count = ans1.shape[0]+ans2.shape[0]+ans3.shape[0]\n",
    "print(count, end=' ')\n",
    "ans1 = ans1[ans1.Group != 'Unknown']\n",
    "ans2 = ans2[ans2.Group != 'Unknown']\n",
    "ans3 = ans3[ans3.Group != 'Unknown']\n",
    "print(ans3.Group.describe().top)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terror frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115 261\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('terrorismData.csv')\n",
    "year = len(set(df['Year']))\n",
    "\n",
    "df =df[df.Country == 'India']\n",
    "df['Casualty'] = df['Killed'] + df['Wounded']\n",
    "jammu_state = df[df.State == 'Jammu and Kashmir']\n",
    "red_corridor = df[(df.State == 'Odisha') | (df.State == 'Jharkhand') | (df.State == 'Andhra Pradesh') |(df['State']=='Chhattisgarh')]\n",
    "red_casualty = int(np.sum(red_corridor['Casualty']))\n",
    "jammu_casualty = int(np.sum(jammu_state['Casualty']))\n",
    "print(red_casualty//year, jammu_casualty//year)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
